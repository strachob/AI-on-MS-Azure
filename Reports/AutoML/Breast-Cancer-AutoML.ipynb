{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# USE CASE\r\n",
        "\r\n",
        "Classify if the breast tumor is malignant or benign. By it's size and placement. The data shown below.\r\n",
        "\r\n",
        "![data-excel](.\\data-excel.png)\r\n",
        "\r\n",
        "Data is explained in **breast-cancer-wisconsin.names** file in the located in the repository.\r\n",
        "\r\n",
        "# Learn AutoMl with UI\r\n",
        "\r\n",
        "I clicked through the UI guideline of making AutoML. It it really simple. I selected Classification as the target method and Class column as column. All other properties and options were autoselected for optimization. Selected machine cost $0.09/h.  The experiment run multiple child model parings to figure out which algorithm has the best accuracy for the job.\r\n",
        "\r\n",
        "![ui-run](.\\ui-run.png)\r\n",
        "\r\n",
        "\r\n",
        "\r\n",
        "And after over 1h later the results came with [VotingEnsemble](https://ml.azure.com/experiments/id/2406bef4-357d-4e25-91f5-f56a73749add/runs/AutoML_ba4a282a-5b8d-46f9-ba48-7749b199b962_43?wsid=/subscriptions/da29bcc9-497c-44b3-95aa-169e164600f6/resourceGroups/AutoML-RG/providers/Microsoft.MachineLearningServices/workspaces/AutoML-Cancer&tid=3b50229c-cd78-4588-9bcf-97b7629e2f0f#model) algorithm as the best one with accuracy equal 97.422%\r\n",
        "\r\n",
        "# First Steps\r\n",
        "\r\n",
        "1. Log into Azure subscription and create Azure Machine Learning resource.\r\n",
        "\r\n",
        "   ![automl-resource](.\\automl-resource.png)\r\n",
        "\r\n",
        "2. Open Machine Learning Studio\r\n",
        "\r\n",
        "3. Import data from **breast-cancer-wisconsin.csv**\r\n",
        "\r\n",
        "4. Create new Notebook and attach a compute module to it. Whem creating compute module watch out for pricing. But more expensive coputation machines will work faster. Which may have bigger impact.\r\n",
        "\r\n",
        "5. Authenticate to Azure by running code below and follow the instructions."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Workspace, Dataset\r\n",
        "\r\n",
        "# Get Workspace defined in by default config.json file\r\n",
        "ws = Workspace.from_config()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "6. Display your imported data."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load Data\r\n",
        "dataset_name = 'Breast-cancer-wisconsin'\r\n",
        "aml_dataset = ws.datasets[dataset_name]\r\n",
        "\r\n",
        "# Use Pandas DataFrame just to sneak peak some data and schema\r\n",
        "full_df = aml_dataset.to_pandas_dataframe()\r\n",
        "full_df.head()"
      ],
      "outputs": [
        {
          "output_type": "execute_result",
          "execution_count": 2,
          "data": {
            "text/plain": "        ID  Clump Thickness  Cell Size  Cell Shape  Marginal Adhesion  \\\n0  1000025                5          1           1                  1   \n1  1002945                5          4           4                  5   \n2  1015425                3          1           1                  1   \n3  1016277                6          8           8                  1   \n4  1017023                4          1           1                  3   \n\n   Epithelial Cell Size Bare Nuclei  Bland Chromatin  Normal Nucleoli  \\\n0                     2           1                3                1   \n1                     7          10                3                2   \n2                     2           2                3                1   \n3                     3           4                3                7   \n4                     2           1                3                1   \n\n   Mitoses  Class  \n0        1      2  \n1        1      2  \n2        1      2  \n3        1      2  \n4        1      2  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ID</th>\n      <th>Clump Thickness</th>\n      <th>Cell Size</th>\n      <th>Cell Shape</th>\n      <th>Marginal Adhesion</th>\n      <th>Epithelial Cell Size</th>\n      <th>Bare Nuclei</th>\n      <th>Bland Chromatin</th>\n      <th>Normal Nucleoli</th>\n      <th>Mitoses</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000025</td>\n      <td>5</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1002945</td>\n      <td>5</td>\n      <td>4</td>\n      <td>4</td>\n      <td>5</td>\n      <td>7</td>\n      <td>10</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1015425</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n      <td>2</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1016277</td>\n      <td>6</td>\n      <td>8</td>\n      <td>8</td>\n      <td>1</td>\n      <td>3</td>\n      <td>4</td>\n      <td>3</td>\n      <td>7</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1017023</td>\n      <td>4</td>\n      <td>1</td>\n      <td>1</td>\n      <td>3</td>\n      <td>2</td>\n      <td>1</td>\n      <td>3</td>\n      <td>1</td>\n      <td>1</td>\n      <td>2</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 2,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609192210066
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data preparation\r\n",
        "As the dataset is not very vast end every column is directly connected to classification of tumor class I will not be deleting any column.\r\n",
        "\r\n",
        "# Spliting data into Train and Test groups\r\n",
        "A model has to be trained on a subset of the data.\r\n",
        "After traning the model has to be tested on the smaller part of data that was not provided for training.\r\n",
        "\r\n",
        "The ratio I have chosen is 80% of data for training and 20% for testing."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset, test_dataset = aml_dataset.random_split(0.8, seed=1)\r\n",
        "\r\n",
        "train_dataset_df = train_dataset.to_pandas_dataframe()\r\n",
        "test_dataset_df = test_dataset.to_pandas_dataframe()\r\n",
        "\r\n",
        "print(train_dataset_df.describe())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                 ID  Clump Thickness   Cell Size  Cell Shape  \\\n",
            "count  5.690000e+02       569.000000  569.000000  569.000000   \n",
            "mean   1.073360e+06         4.405975    3.175747    3.237258   \n",
            "std    5.929028e+05         2.756944    3.101688    3.002045   \n",
            "min    6.163400e+04         1.000000    1.000000    1.000000   \n",
            "25%    8.783580e+05         2.000000    1.000000    1.000000   \n",
            "50%    1.171578e+06         4.000000    1.000000    2.000000   \n",
            "75%    1.237674e+06         6.000000    5.000000    5.000000   \n",
            "max    1.345435e+07        10.000000   10.000000   10.000000   \n",
            "\n",
            "       Marginal Adhesion  Epithelial Cell Size  Bland Chromatin  \\\n",
            "count         569.000000            569.000000       569.000000   \n",
            "mean            2.850615              3.270650         3.455185   \n",
            "std             2.876049              2.282172         2.437640   \n",
            "min             1.000000              1.000000         1.000000   \n",
            "25%             1.000000              2.000000         2.000000   \n",
            "50%             1.000000              2.000000         3.000000   \n",
            "75%             4.000000              4.000000         4.000000   \n",
            "max            10.000000             10.000000        10.000000   \n",
            "\n",
            "       Normal Nucleoli     Mitoses       Class  \n",
            "count       569.000000  569.000000  569.000000  \n",
            "mean          2.889279    1.611599    2.685413  \n",
            "std           3.062157    1.761863    0.950064  \n",
            "min           1.000000    1.000000    2.000000  \n",
            "25%           1.000000    1.000000    2.000000  \n",
            "50%           1.000000    1.000000    2.000000  \n",
            "75%           4.000000    1.000000    4.000000  \n",
            "max          10.000000   10.000000    4.000000  \n"
          ]
        }
      ],
      "execution_count": 3,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609193166810
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Connect to Compute Unit\r\n",
        "We will select \"Notebook-Breast\" compute instance created at the beggining."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import AmlCompute\r\n",
        "from azureml.core.compute import ComputeTarget\r\n",
        "\r\n",
        "amlcompute_cluster_name = \"Notebook-Breast\"\r\n",
        "\r\n",
        "found = False\r\n",
        "cts = ws.compute_targets\r\n",
        "\r\n",
        "if amlcompute_cluster_name in cts and cts[amlcompute_cluster_name].type == 'ComputeInstance':\r\n",
        "     found = True\r\n",
        "     print('Found existing training cluster.')\r\n",
        "     # Get existing cluster\r\n",
        "     # Method 1:\r\n",
        "     aml_remote_compute = cts[amlcompute_cluster_name]\r\n",
        "     # Method 2:\r\n",
        "     # aml_remote_compute = ComputeTarget(ws, amlcompute_cluster_name)\r\n",
        "    \r\n",
        "if not found:\r\n",
        "     print('Creating a new training cluster...')\r\n",
        "     provisioning_config = AmlCompute.provisioning_configuration(vm_size = \"STANDARD_D13_V2\", # for GPU, use \"STANDARD_NC12\"\r\n",
        "                                                                 #vm_priority = 'lowpriority', # optional\r\n",
        "                                                                 max_nodes = 20)\r\n",
        "     # Create the cluster.\r\n",
        "     aml_remote_compute = ComputeTarget.create(ws, amlcompute_cluster_name, provisioning_config)\r\n",
        "    \r\n",
        "print('Checking cluster status...')\r\n",
        "\r\n",
        "aml_remote_compute.wait_for_completion(show_output = True)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found existing training cluster.\n",
            "Checking cluster status...\n",
            "\n",
            "Running\n"
          ]
        }
      ],
      "execution_count": 5,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609193814725
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Primary metric for Classification\r\n",
        "\r\n",
        "I will use just the Accuracy as the primary metric for the Classification method. It is the most simple to get and to understand.\r\n",
        "\r\n",
        "Values from 0 to 1. Closer to one is better.\r\n",
        "\r\n",
        "# Define AutoML Experiment settings (With AML Remote Compute)\r\n",
        "Lets define the run configuration.\r\n",
        "We set:\r\n",
        "\r\n",
        "*classification* as task we are doing\r\n",
        "\r\n",
        "*accuracy* as a primary metric to be calculated\r\n",
        "\r\n",
        "**Accuracy** is the ratio of predictions that exactly match the true class labels\r\n",
        "\r\n",
        "**Class** column as the target column."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\r\n",
        "import os\r\n",
        "\r\n",
        "from azureml.train.automl import AutoMLConfig\r\n",
        "\r\n",
        "project_folder = './strachob'\r\n",
        "os.makedirs(project_folder, exist_ok=True)\r\n",
        "\r\n",
        "automl_config = AutoMLConfig(compute_target=aml_remote_compute,\r\n",
        "                             task='classification',\r\n",
        "                             primary_metric='accuracy',\r\n",
        "                             experiment_timeout_minutes=15,                            \r\n",
        "                             training_data=train_dataset,\r\n",
        "                             label_column_name=\"Class\",\r\n",
        "                             n_cross_validations=5,\r\n",
        "                             # blacklist_models='XGBoostClassifier', \r\n",
        "                             # iteration_timeout_minutes=5,                                                    \r\n",
        "                             enable_early_stopping=True,\r\n",
        "                             featurization='auto',\r\n",
        "                             debug_log='automated_ml_errors.log',\r\n",
        "                             verbosity=logging.INFO,\r\n",
        "                             path=project_folder\r\n",
        "                             )"
      ],
      "outputs": [],
      "execution_count": 7,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609230740756
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Run the experiment\r\n",
        "\r\n",
        "!!! Beware it can take some time (up to an hour) !!!"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Experiment\r\n",
        "from datetime import datetime\r\n",
        "\r\n",
        "now = datetime.now()\r\n",
        "time_string = now.strftime(\"%m-%d-%Y-%H\")\r\n",
        "experiment_name = \"classify-automl-remote-{0}\".format(time_string)\r\n",
        "print(experiment_name)\r\n",
        "\r\n",
        "experiment = Experiment(workspace=ws, name=experiment_name)\r\n",
        "\r\n",
        "import time\r\n",
        "start_time = time.time()\r\n",
        "            \r\n",
        "run = experiment.submit(automl_config, show_output=True)\r\n",
        "\r\n",
        "print('Manual run timing: --- %s seconds needed for running the whole Remote AutoML Experiment ---' % (time.time() - start_time))"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "classify-automl-remote-12-29-2020-08\n",
            "Running on remote.\n",
            "No run_configuration provided, running on Notebook-Breast with default configuration\n",
            "Running on remote compute: Notebook-Breast\n",
            "Parent Run ID: AutoML_2294fdb5-c6f2-4570-84f5-08b500378b62\n",
            "\n",
            "Current status: FeaturesGeneration. Generating features for the dataset.\n",
            "Current status: DatasetCrossValidationSplit. Generating individually featurized CV splits.\n",
            "Current status: ModelSelection. Beginning model selection.\n",
            "\n",
            "****************************************************************************************************\n",
            "DATA GUARDRAILS: \n",
            "\n",
            "TYPE:         Class balancing detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and all classes are balanced in your training data.\n",
            "              Learn more about imbalanced data: https://aka.ms/AutomatedMLImbalancedData\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         Missing feature values imputation\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  No feature missing values were detected in the training data.\n",
            "              Learn more about missing value imputation: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "TYPE:         High cardinality feature detection\n",
            "STATUS:       PASSED\n",
            "DESCRIPTION:  Your inputs were analyzed, and no high cardinality features were detected.\n",
            "              Learn more about high cardinality feature handling: https://aka.ms/AutomatedMLFeaturization\n",
            "\n",
            "****************************************************************************************************\n",
            "\n",
            "****************************************************************************************************\n",
            "ITERATION: The iteration being evaluated.\n",
            "PIPELINE: A summary description of the pipeline being evaluated.\n",
            "DURATION: Time taken for the current iteration.\n",
            "METRIC: The result of computing score on the fitted pipeline.\n",
            "BEST: The best observed score thus far.\n",
            "****************************************************************************************************\n",
            "\n",
            " ITERATION   PIPELINE                                       DURATION      METRIC      BEST\n",
            "         0   MaxAbsScaler LightGBM                          0:00:44       0.9437    0.9437\n",
            "         1   MaxAbsScaler XGBoostClassifier                 0:00:46       0.9454    0.9454\n",
            "         2   MaxAbsScaler RandomForest                      0:00:41       0.9560    0.9560\n",
            "         3   MaxAbsScaler RandomForest                      0:00:45       0.9385    0.9560\n",
            "         4   MaxAbsScaler RandomForest                      0:00:45       0.9525    0.9560\n",
            "         5   MaxAbsScaler RandomForest                      0:00:46       0.9490    0.9560\n",
            "         6   SparseNormalizer XGBoostClassifier             0:00:45       0.9420    0.9560\n",
            "         7   MaxAbsScaler RandomForest                      0:00:51       0.9578    0.9578\n",
            "         8   SparseNormalizer LightGBM                      0:00:42       0.9437    0.9578\n",
            "         9   MaxAbsScaler LogisticRegression                0:00:42       0.9402    0.9578\n",
            "        10   MaxAbsScaler LightGBM                          0:00:42       0.9542    0.9578\n",
            "        11   SparseNormalizer XGBoostClassifier             0:00:40       0.9455    0.9578\n",
            "        12   MaxAbsScaler RandomForest                      0:00:41       0.9349    0.9578\n",
            "        13   StandardScalerWrapper LightGBM                 0:00:48       0.9244    0.9578\n",
            "        14   SparseNormalizer XGBoostClassifier             0:00:44       0.9542    0.9578\n",
            "        15   SparseNormalizer XGBoostClassifier             0:00:49       0.9507    0.9578\n",
            "        16    VotingEnsemble                                0:01:03       0.9648    0.9648\n",
            "        17    StackEnsemble                                 0:01:03       0.9542    0.9648\n",
            "Manual run timing: --- 1425.9323275089264 seconds needed for running the whole Remote AutoML Experiment ---\n"
          ]
        }
      ],
      "execution_count": 8,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609232218612
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Find the Best Model and Show run details\r\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\r\n",
        "import datetime as dt\r\n",
        "\r\n",
        "run_details = run.get_details()\r\n",
        "\r\n",
        "# Like: 2020-01-12T23:11:56.292703Z\r\n",
        "end_time_utc_str = run_details['endTimeUtc'].split(\".\")[0]\r\n",
        "start_time_utc_str = run_details['startTimeUtc'].split(\".\")[0]\r\n",
        "timestamp_end = time.mktime(datetime.strptime(end_time_utc_str, \"%Y-%m-%dT%H:%M:%S\").timetuple())\r\n",
        "timestamp_start = time.mktime(datetime.strptime(start_time_utc_str, \"%Y-%m-%dT%H:%M:%S\").timetuple())\r\n",
        "\r\n",
        "parent_run_time = timestamp_end - timestamp_start\r\n",
        "print('Run Timing: --- %s seconds needed for running the whole Remote AutoML Experiment ---' % (parent_run_time))\r\n",
        "\r\n",
        "\r\n",
        "## Best model\r\n",
        "\r\n",
        "\r\n",
        "best_run, fitted_model = run.get_output()\r\n",
        "print(best_run)\r\n",
        "print(fitted_model)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Run Timing: --- 1395.0 seconds needed for running the whole Remote AutoML Experiment ---\n",
            "Run(Experiment: classify-automl-remote-12-29-2020-08,\n",
            "Id: AutoML_2294fdb5-c6f2-4570-84f5-08b500378b62_16,\n",
            "Type: azureml.scriptrun,\n",
            "Status: Completed)\n",
            "Pipeline(memory=None,\n",
            "         steps=[('datatransformer',\n",
            "                 DataTransformer(enable_dnn=None, enable_feature_sweeping=None,\n",
            "                                 feature_sweeping_config=None,\n",
            "                                 feature_sweeping_timeout=None,\n",
            "                                 featurization_config=None, force_text_dnn=None,\n",
            "                                 is_cross_validation=None,\n",
            "                                 is_onnx_compatible=None, logger=None,\n",
            "                                 observer=None, task=None, working_dir=None)),\n",
            "                ('prefittedsoftvotingclassifier',...\n",
            "                                                                                                    min_samples_leaf=0.01,\n",
            "                                                                                                    min_samples_split=0.2442105263157895,\n",
            "                                                                                                    min_weight_fraction_leaf=0.0,\n",
            "                                                                                                    n_estimators=10,\n",
            "                                                                                                    n_jobs=1,\n",
            "                                                                                                    oob_score=False,\n",
            "                                                                                                    random_state=None,\n",
            "                                                                                                    verbose=0,\n",
            "                                                                                                    warm_start=False))],\n",
            "                                                                     verbose=False))],\n",
            "                                               flatten_transform=None,\n",
            "                                               weights=[0.2222222222222222,\n",
            "                                                        0.3333333333333333,\n",
            "                                                        0.1111111111111111,\n",
            "                                                        0.1111111111111111,\n",
            "                                                        0.1111111111111111,\n",
            "                                                        0.1111111111111111]))],\n",
            "         verbose=False)\n"
          ]
        }
      ],
      "execution_count": 11,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609232690876
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "So it turns out the best model for this particular use case was \"Prefitted Soft Voting Classifier\"\r\n",
        "\r\n",
        "# Prepare data for testing and classify testing data\r\n",
        "Pop Class column from test data. It has to be classified."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\r\n",
        "\r\n",
        "#Remove Label/y column\r\n",
        "if 'Class' in test_dataset_df.columns:\r\n",
        "    y_test_df = test_dataset_df.pop('Class')\r\n",
        "\r\n",
        "x_test_df = test_dataset_df\r\n",
        "\r\n",
        "\r\n",
        "# Try the best model\r\n",
        "y_predictions = fitted_model.predict(x_test_df)\r\n",
        "\r\n",
        "print('10 predictions: ')\r\n",
        "print(y_predictions[:10])\r\n",
        "\r\n",
        "y_predictions.shape\r\n",
        "\r\n",
        "\r\n",
        "## Show the accuracy\r\n",
        "\r\n",
        "from sklearn.metrics import accuracy_score\r\n",
        "\r\n",
        "print('Accuracy:')\r\n",
        "accuracy_score(y_test_df, y_predictions)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10 predictions: \n",
            "[4 2 4 2 2 4 4 4 4 2]\n",
            "Accuracy:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "execution_count": 16,
          "data": {
            "text/plain": "0.9692307692307692"
          },
          "metadata": {}
        }
      ],
      "execution_count": 16,
      "metadata": {
        "collapsed": true,
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1609233797039
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This time accuracy was on the verge of 97% but it took 1/4 of time."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3-azureml",
      "language": "python",
      "display_name": "Python 3.6 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3-azureml"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}